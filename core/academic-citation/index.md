# Academic Citation

We have been asked a few times about how to cite Pupil Core in academic research. Please take a look at our papers below for citation options. If you're using Pupil Core as a tool in your research please cite the below UbiComp 2014 paper.

For guidance on citing Pupil Invisible please see [here](/invisible/publications/).

## Papers that cite Pupil Core

We have compiled a list of academic publications that use Pupil Labs products. You can find it [here](https://pupil-labs.com/publications/)!

## UbiComp 2014 Paper

#### Title

Pupil: An Open Source Platform for Pervasive Eye Tracking and Mobile Gaze-based Interaction

#### Abstract

In this paper we present Pupil -- an accessible, affordable, and extensible open source platform for pervasive eye tracking and gaze-based interaction. Pupil comprises 1) a light-weight eye tracking headset, 2) an open source software framework for mobile eye tracking, as well as 3) a graphical user interface to playback and visualize video and gaze data. Pupil features high-resolution scene and eye cameras for monocular and binocular gaze estimation. The software and GUI are platform-independent and include state-of-the-art algorithms for real-time pupil detection and tracking, calibration, and accurate gaze estimation. Results of a performance evaluation show that Pupil can provide an average gaze estimation accuracy of 0.6 degree of visual angle (0.08 degree precision) with a processing pipeline latency of only 0.045 seconds.

#### Permalink to article

Available on dl.acm.org: [http://dl.acm.org/citation.cfm?doid=2638728.2641695](http://dl.acm.org/citation.cfm?doid=2638728.2641695)

> BibTeX Style Citation

```
@inproceedings{Kassner:2014:POS:2638728.2641695,
 author = {Kassner, Moritz and Patera, William and Bulling, Andreas},
 title = {Pupil: An Open Source Platform for Pervasive Eye Tracking and Mobile Gaze-based Interaction},
 booktitle = {Adjunct Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
 series = {UbiComp '14 Adjunct},
 year = {2014},
 isbn = {978-1-4503-3047-3},
 location = {Seattle, Washington},
 pages = {1151--1160},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2638728.2641695},
 doi = {10.1145/2638728.2641695},
 acmid = {2641695},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {eye movement, gaze-based interaction, mobile eye tracking, wearable computing},
}
```

## Pupil Technical Report

#### Title

Pupil: An Open Source Platform for Pervasive Eye Tracking and Mobile Gaze-based Interaction

#### Abstract

Commercial head-mounted eye trackers provide useful features to customers in industry and research but are expensive and rely on closed source hardware and software. This limits the application areas and use of mobile eye tracking to expert users and inhibits user-driven development, customization, and extension. In this paper we present Pupil -- an accessible, affordable, and extensible open source platform for mobile eye tracking and gaze-based interaction. Pupil comprises 1) a light-weight headset with high-resolution cameras, 2) an open source software framework for mobile eye tracking, as well as 3) a graphical user interface (GUI) to playback and visualize video and gaze data. Pupil features high-resolution scene and eye cameras for monocular and binocular gaze estimation. The software and GUI are platform-independent and include state-of-the-art algorithms for real-time pupil detection and tracking, calibration, and accurate gaze estimation. Results of a performance evaluation show that Pupil can provide an average gaze estimation accuracy of 0.6 degree of visual angle (0.08 degree precision) with a latency of the processing pipeline of only 0.045 seconds.

#### Permalink to article

Available on arxiv.org: [http://arxiv.org/abs/1405.0006](http://arxiv.org/abs/1405.0006)

> BibTeX Style Citation

```
@article{KassnerPateraBulling:2014,
  author={Kassner, Moritz and Patera, William and Bulling, Andreas},
  title={Pupil: An Open Source Platform for Pervasive Eye Tracking and Mobile Gaze-based Interaction},
  keywords={Eye Movement, Mobile Eye Tracking, Wearable Computing, Gaze-based Interaction},
  year={2014},
  month={April},
  archivePrefix = "arXiv",
  eprint        = "1405.0006",
  primaryClass  = "cs-cv",
  url = {http://arxiv.org/abs/1405.0006}
}
```

## MIT Thesis

#### Abstract

This thesis explores the nature of a human experience in space through a primary inquiry into vision. This inquiry begins by questioning the existing methods and instruments employed to capture and represent a human experience of space. While existing qualitative and quantitative methods and instruments -- from "subjective" interviews to "objective" photographic documentation -- may lead to insight in the study of a human experience in space, we argue that they are inherently limited with respect to physiological realities. As one moves about the world, one believes to see the world as continuous and fully resolved. However, this is not how human vision is currently understood to function on a physiological level. If we want to understand how humans visually construct a space, then we must examine patterns of visual attention on a physiological level. In order to inquire into patterns of visual attention in three dimensional space, we need to develop new instruments and new methods of representation. The instruments we require, directly address the physiological realities of vision, and the methods of representation seek to situate the human subject within a space of their own construction. In order to achieve this goal we have developed Pupil, a custom set of hardware and software instruments, that capture the subject's eye movements. Using Pupil, we have conducted a series of trials from proof of concept -- demonstrating the capabilities of our instruments -- to critical inquiry of the relationship between a human subject and a space. We have developed software to visualize this unique spatial experience, and have posed open questions based on the initial findings of our trials. This thesis aims to contribute to spatial design disciplines, by providing a new way to capture and represent a human experience of space.

(Authors names appear in alphabetical order - equal hierarchy in authorship.)

#### Permalink to Thesis

On MIT DSpace: [http://hdl.handle.net/1721.1/72626](http://hdl.handle.net/1721.1/72626)

> BibTeX Style Citation

```
@mastersthesis{Kassner:Patera:2012,
  title={{PUPIL: Constructing the Space of Visual Attention}},
  author={Kassner, Moritz Philipp and Patera, William Rhoades},
  year={2012},
  school={Massachusetts Institute of Technology},
  url={http://hdl.handle.net/1721.1/72626}
}
```
> Chicago Style Citation

```
Moritz Kassner, William Patera, Pupil: Constructing the Space of Visual Attention, SMArchS Master Thesis, (Cambridge: Massachusetts Institute of Technology, 2012).
```

> APA Style Citation

```
Kassner, M., & Patera, W. (2012). Pupil: Constructing the space of visual attention (Unpublished masterâ€™s thesis). Massachusetts Institute of Technology, Cambridge, MA. Available from http://hdl.handle.net/1721.1/72626
```

## Link to Repository

You are also welcome to link to our code repositories: [Pupil Github Repository](https://github.com/pupil-labs/pupil)

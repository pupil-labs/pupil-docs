{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync with External Sensors\n",
    "\n",
    "Many experimental setups record data from multiple sensors in parallel. This data needs to be synced temporally for a joint analysis. All eye tracking data you record with Pupil Invisible is accurately timestamped, which makes this easily possible.\n",
    "\n",
    "In this guide you will learn how to sync eye tracking data from Pupil Invisible to any other timestamped external sensor using the `pd.merge_asof` function of Pandas. As an example, we will sync a heart rate sensor with a Pupil Invisible recording to produce a gaze overlay visualization with real-time heart rate of a man jogging.\n",
    "\n",
    "TODO\n",
    "- What heart rate sensor die we use?\n",
    "\n",
    "## Dependencies of this Guide\n",
    "To be written.\n",
    "- Required Python libs\n",
    "    - pandas av fitdecode tqdm opencv-python\n",
    "- Where to download the code\n",
    "- Where to download the example data\n",
    "- How to put data into data folder\n",
    "\n",
    "## Loading all Data\n",
    "For the example visualization we need the scene video and gaze data from the Pupil Invisible recording, and the heart rate data from the [??]() recording.\n",
    "\n",
    "The heart rate data can be read using the `fitdecode` module. For more details check out the implementation of the [load_fit_data]() implementation.\n",
    "\n",
    "The gaze data CSV file can be read using Pandas. All we need from it is the timestamps and the gaze values.\n",
    "\n",
    "For the scene video, we initially only need its timestamps and the corresponding frame indices for matching, we don't have to touch the actual video frames yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from decode_fit import load_fit_data\n",
    "\n",
    "\n",
    "fit_path = \"data/eye-tracking-run.FIT\"\n",
    "fit = load_fit_data(fit_path)\n",
    "\n",
    "gaze_path = \"data/demo-recording/running_rd-4a40d94d/gaze.csv\"\n",
    "gaze = pd.read_csv(gaze_path)\n",
    "gaze[\"timestamp [ns]\"] = pd.to_datetime(gaze[\"timestamp [ns]\"])\n",
    "gaze = gaze[[\"timestamp [ns]\", \"gaze x [px]\", \"gaze y [px]\"]]\n",
    "\n",
    "world_ts_path = \"data/demo-recording/running_rd-4a40d94d/world_timestamps.csv\"\n",
    "world_ts = pd.read_csv(world_ts_path)\n",
    "world_ts[\"frame_index\"] = world_ts.index\n",
    "world_ts[\"timestamp [ns]\"] = pd.to_datetime(world_ts[\"timestamp [ns]\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section id</th>\n",
       "      <th>recording id</th>\n",
       "      <th>timestamp [ns]</th>\n",
       "      <th>frame_index</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cadence</th>\n",
       "      <th>speed</th>\n",
       "      <th>gaze x [px]</th>\n",
       "      <th>gaze y [px]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3e2512bf-4389-42f4-86af-20feebe937e8</td>\n",
       "      <td>4a40d94d-7fbd-439b-be98-7ac7cf2c13c2</td>\n",
       "      <td>2022-07-09 17:19:08.694</td>\n",
       "      <td>0</td>\n",
       "      <td>56.140768</td>\n",
       "      <td>10.187518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-09 17:20:19</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>464.678</td>\n",
       "      <td>747.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3e2512bf-4389-42f4-86af-20feebe937e8</td>\n",
       "      <td>4a40d94d-7fbd-439b-be98-7ac7cf2c13c2</td>\n",
       "      <td>2022-07-09 17:19:08.744</td>\n",
       "      <td>1</td>\n",
       "      <td>56.140768</td>\n",
       "      <td>10.187518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-09 17:20:19</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>464.678</td>\n",
       "      <td>747.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3e2512bf-4389-42f4-86af-20feebe937e8</td>\n",
       "      <td>4a40d94d-7fbd-439b-be98-7ac7cf2c13c2</td>\n",
       "      <td>2022-07-09 17:19:08.794</td>\n",
       "      <td>2</td>\n",
       "      <td>56.140768</td>\n",
       "      <td>10.187518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-09 17:20:19</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>464.678</td>\n",
       "      <td>747.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3e2512bf-4389-42f4-86af-20feebe937e8</td>\n",
       "      <td>4a40d94d-7fbd-439b-be98-7ac7cf2c13c2</td>\n",
       "      <td>2022-07-09 17:19:08.844</td>\n",
       "      <td>3</td>\n",
       "      <td>56.140768</td>\n",
       "      <td>10.187518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-09 17:20:19</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>464.678</td>\n",
       "      <td>747.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3e2512bf-4389-42f4-86af-20feebe937e8</td>\n",
       "      <td>4a40d94d-7fbd-439b-be98-7ac7cf2c13c2</td>\n",
       "      <td>2022-07-09 17:19:08.894</td>\n",
       "      <td>4</td>\n",
       "      <td>56.140768</td>\n",
       "      <td>10.187518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-09 17:20:19</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>464.678</td>\n",
       "      <td>747.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             section id                          recording id  \\\n",
       "0  3e2512bf-4389-42f4-86af-20feebe937e8  4a40d94d-7fbd-439b-be98-7ac7cf2c13c2   \n",
       "1  3e2512bf-4389-42f4-86af-20feebe937e8  4a40d94d-7fbd-439b-be98-7ac7cf2c13c2   \n",
       "2  3e2512bf-4389-42f4-86af-20feebe937e8  4a40d94d-7fbd-439b-be98-7ac7cf2c13c2   \n",
       "3  3e2512bf-4389-42f4-86af-20feebe937e8  4a40d94d-7fbd-439b-be98-7ac7cf2c13c2   \n",
       "4  3e2512bf-4389-42f4-86af-20feebe937e8  4a40d94d-7fbd-439b-be98-7ac7cf2c13c2   \n",
       "\n",
       "           timestamp [ns]  frame_index   latitude  longitude  altitude  \\\n",
       "0 2022-07-09 17:19:08.694            0  56.140768  10.187518       NaN   \n",
       "1 2022-07-09 17:19:08.744            1  56.140768  10.187518       NaN   \n",
       "2 2022-07-09 17:19:08.794            2  56.140768  10.187518       NaN   \n",
       "3 2022-07-09 17:19:08.844            3  56.140768  10.187518       NaN   \n",
       "4 2022-07-09 17:19:08.894            4  56.140768  10.187518       NaN   \n",
       "\n",
       "            timestamp  heart_rate  cadence  speed  gaze x [px]  gaze y [px]  \n",
       "0 2022-07-09 17:20:19          95        0    0.0      464.678      747.029  \n",
       "1 2022-07-09 17:20:19          95        0    0.0      464.678      747.029  \n",
       "2 2022-07-09 17:20:19          95        0    0.0      464.678      747.029  \n",
       "3 2022-07-09 17:20:19          95        0    0.0      464.678      747.029  \n",
       "4 2022-07-09 17:20:19          95        0    0.0      464.678      747.029  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge_asof(world_ts, fit, left_on=\"timestamp [ns]\", right_on=\"timestamp\", direction=\"nearest\")\n",
    "df = pd.merge_asof(df, gaze, left_on=\"timestamp [ns]\", right_on=\"timestamp [ns]\", direction=\"nearest\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "\n",
    "cut_off_index = 15000\n",
    "world_vid_path = \"/Users/marc/Downloads/raw-data-export (2)/running_rd-4a40d94d/3e2512bf_0.0-2504.94.mp4\"\n",
    "world_lookup = {}\n",
    "for index, packet in enumerate(av.open(world_vid_path).demux(video=0)):\n",
    "    world_lookup[index] = packet\n",
    "    \n",
    "    if index == cut_off_index:\n",
    "        break\n",
    "\n",
    "world_ts = world_ts.iloc[:cut_off_index]\n",
    "\n",
    "vis_vid_path = \"/Users/marc/Downloads/raw-data-export (2)/running_rd-4a40d94d/vis.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if idx < 30 * 60 * 10:\n",
    "        continue\n",
    "    \n",
    "    frame = world_lookup[row[\"frame_index\"]].decode()\n",
    "    try:\n",
    "        frame = frame[0]\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "    img = frame.to_ndarray(format=\"bgr24\")\n",
    "    \n",
    "    gaze = (int(row[\"gaze x [px]\"]), int(row[\"gaze y [px]\"]))\n",
    "    cv2.circle(img, gaze, 50, (0, 0, 255), 5)\n",
    "    \n",
    "    heart_rate = row[\"heart_rate\"]\n",
    "    cv2.putText(img, f\"HR: {heart_rate}\", (50,100), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,0,0), 3)\n",
    "\n",
    "    cv2.imshow(\"Scene Video + Gaze + Heartrate\", img)\n",
    "    key = cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvenc not available h264_nvenc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/15000 [00:00<11:08, 22.40 frames/s] /var/folders/k3/8x0h0s854dq0jc83qmhmzn3w0000gn/T/ipykernel_3690/4244152212.py:16: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure()\n",
      "  5%|â–         | 743/15000 [00:46<14:50, 16.00 frames/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def visualize(img, df, idx):\n",
    "    row = df.iloc[idx]\n",
    "    gaze = (int(row[\"gaze x [px]\"]), int(row[\"gaze y [px]\"]))\n",
    "    cv2.circle(img, gaze, 50, (0, 0, 255), 5)\n",
    "    \n",
    "    heart_rate = row[\"heart_rate\"]\n",
    "    cv2.putText(img, f\"HR: {heart_rate}\", (50,100), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,0,0), 3)\n",
    "\n",
    "    # Make a random plot...\n",
    "    fig = plt.figure()\n",
    "    # ax = fig.add_subplot(111)\n",
    "\n",
    "    pad = 50\n",
    "    heart_rate = df.iloc[idx - pad: idx + pad].heart_rate\n",
    "\n",
    "    plt.plot(np.arange(len(heart_rate)) + idx - pad, heart_rate, color=\"blue\")\n",
    "    plt.xlim(idx - pad, idx + pad)\n",
    "\n",
    "    # If we haven't already shown or saved the plot, then we need to\n",
    "    # draw the figure first...\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Now we can save it to a numpy array.\n",
    "    data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    w_v, h_v, _ = data.shape\n",
    "    w, h, _ = img.shape\n",
    "\n",
    "    img[w-w_v:w, 0:h_v, :] = data\n",
    "\n",
    "    return img\n",
    "\n",
    "original_container = av.open(str(world_vid_path))\n",
    "original_video_stream = original_container.streams.video[0]\n",
    "\n",
    "visualization_container = av.open(str(vis_vid_path), \"w\")\n",
    "\n",
    "try:\n",
    "    visualization_video = visualization_container.add_stream(\"h264_nvenc\")\n",
    "except Exception as e:\n",
    "    print(\"nvenc not available\", e)\n",
    "    visualization_video = visualization_container.add_stream(\"h264\")\n",
    "\n",
    "visualization_video.options[\"bf\"] = \"0\"\n",
    "visualization_video.options[\"movflags\"] = \"faststart\"\n",
    "visualization_video.gop_size = original_video_stream.gop_size\n",
    "visualization_video.codec_context.height = original_video_stream.height\n",
    "visualization_video.codec_context.width = original_video_stream.width\n",
    "visualization_video.codec_context.time_base = original_video_stream.time_base\n",
    "visualization_video.codec_context.bit_rate = original_video_stream.bit_rate\n",
    "\n",
    "progress = tqdm(unit=\" frames\", total=len(df))\n",
    "with visualization_container:\n",
    "    for idx, row in df.iterrows():\n",
    "        frame = world_lookup[row[\"frame_index\"]].decode()\n",
    "        try:\n",
    "            frame = frame[0]\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "        img = frame.to_ndarray(format=\"bgr24\")\n",
    "        vis_img = visualize(img, df, idx)\n",
    "\n",
    "        # cv2.imshow(\"Scene Video + Gaze + Heartrate\", vis_img)\n",
    "        # cv2.waitKey(1)\n",
    "        \n",
    "        new_frame = frame.from_ndarray(vis_img, format=\"bgr24\")\n",
    "        new_frame.pts = frame.pts\n",
    "        new_frame.time_base = original_video_stream.time_base\n",
    "        packets = visualization_video.encode(new_frame)\n",
    "        progress.update()\n",
    "        visualization_container.mux(packets)\n",
    "    # encode and mux frames that have been queued internally by the encoders\n",
    "    visualization_container.mux(visualization_video.encode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sensor-sync')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d87e97d5eb72e6239d630360e86afce37607673c01853624d91291a4f555ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

[
  {
    "title": "Undistort Video and Gaze Data",
    "details": "Learn how to undistort the scene camera distortions and apply it to gaze positions.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/undistort/"
    },
    "image": "/alpha-lab/undist.webp",
    "category": "Other/Core"
  },
  {
    "title": "Use Neon with Pupil Capture",
    "details": "Use your Neon module as if you were using Pupil Core. Connect it to a laptop, and record using Pupil Capture.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/neon-with-capture/"
    },
    "image": "/alpha-lab/neon-capture.webp",
    "category": "Other/Core"
  },
  {
    "title": "Map Gaze Onto Dynamic Screen Content",
    "details": "Map and visualise gaze onto a screen with dynamic content, e.g. a video, web browsing, or other, using Pupil Cloud's Reference Image Mapper and screen recording software.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/map-your-gaze-to-a-2d-screen/#map-and-visualise-gaze-onto-a-display-content-using-the-reference-image-mapper"
    },
    "image": "/alpha-lab/map-gaze-screen.webp",
    "category": "Screens & Interfaces"
  },
  {
    "title": "Map Gaze Onto Body Parts",
    "details": "Map gaze behaviour on body parts that appear in the scene video of Neon or Pupil Invisible eye tracking footage.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/dense-pose/#map-gaze-onto-body-parts-using-densepose"
    },
    "image": "/alpha-lab/map-gaze-body.webp",
    "category": "Around People"
  },
  {
    "title": "Map Gaze Throughout an Entire Room",
    "details": "Use Pupil Cloud's Reference Image Mapper to Map gaze onto multiple areas of an entire room as participants freely navigate around it.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/multiple-rim/#map-and-visualize-gaze-on-multiple-reference-images-taken-from-the-same-environment"
    },
    "image": "/alpha-lab/multiple-ref-mapper-enrich.webp",
    "category": "3D Spaces"
  },
  {
    "title": "Generate Scanpath Visualisations",
    "details": "Generate both static and dynamic scanpath visualisations using exported data from Pupil Cloud's Reference Image Mapper or Manual Mapper.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/scanpath-rim/#generate-static-and-dynamic-scanpaths"
    },
    "image": "/alpha-lab/scanpath_image_nad.webp",
    "category": "Other/Core"
  },
  {
    "title": "Uncover Gaze Behaviour on Phones",
    "details": "Capture and analyze users' viewing behaviour when focusing on small icons and features of mobile applications using Neon eye tracking alongside existing Cloud and Alpha Lab tools.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/phone-neon/#uncover-gaze-behaviour-on-phone-screens-with-neon"
    },
    "image": "/alpha-lab/gaze-behavior-phone-neon.webp",
    "category": "Screens & Interfaces"
  },
  {
    "title": "Map Gaze Onto a 3D Model of an Environment",
    "details": "Map gaze onto a 3D model of an environment and visualise gaze patterns as 3D heatmaps using Pupil Cloud's Reference Image Mapper and Nerfstudio.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/nerfs/#create-3d-models-of-your-environment-using-reference-image-mapper-and-nerfstudio"
    },
    "image": "/alpha-lab/map-gaze-3d-nerf.webp",
    "category": "3D Spaces"
  },
  {
    "title": "Build Gaze-Contingent Assistive Applications",
    "details": "Build your very own gaze-contingent assistive applications (such as a gaze-controlled input device) using Neon eye tracking and our real-time screen gaze package.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/gaze-contingency-assistive/#a-practical-guide-to-implementing-gaze-contingency-for-assistive-technology"
    },
    "image": "/alpha-lab/build-gaze-assistive-neon.webp",
    "category": "Real Time & Interactive"
  },
  {
    "title": "Detect Eye Blinks With Neon",
    "details": "Apply Pupil Labs blink detection algorithm to Neon recordings programmatically, offline or in real-time using Pupil Labs real-time Python API.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/blink-detection/#detecting-eye-blinks-using-pupil-labs-blink-detection-pipeline"
    },
    "image": "/alpha-lab/blink.webp",
    "category": "Real Time & Interactive"
  },
  {
    "title": "Build an AI Vision Assistant",
    "details": "Experiment with assistive scene understanding applications using GPT-4V (an extension of GPT4 that can interpret images) and Pupil Labs eye tracking.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/gpt4-eyes/"
    },
    "image": "/alpha-lab/gpt4-eyes.webp",
    "category": "Building with AI"
  },
  {
    "title": "Automate AOI Masking in Pupil Cloud",
    "details": "Extend the capabilities of Pupil Cloud’s AOI tool by automatically segmenting and drawing masks using natural language.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/gaze-metrics-in-aois/"
    },
    "image": "/alpha-lab/aoi-demo.webp",
    "category": "Building with AI"
  },
  {
    "title": "Map Gaze Onto Facial Landmarks",
    "details": "Map gaze onto facial landmarks using Pupil Cloud’s Face Mapper exported data.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/gaze-on-face/"
    },
    "image": "/alpha-lab/map-gaze-nadia.webp",
    "category": "Around People"
  },
  {
    "title": "Map Gaze Onto Website AOIs",
    "details": "Define areas of interest on a website and map gaze onto them using our Web-AOI tool.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/web-aois/"
    },
    "image": "/alpha-lab/web-aoi.webp",
    "category": "Screens & Interfaces"
  },
  {
    "title": "Map Gaze Into a User-Supplied 3D Model",
    "details": "Map gaze, head pose, and observer position into a 3D coordinate system of your choice using our Tag Aligner tool.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/tag-aligner/"
    },
    "image": "/alpha-lab/tag-aligner.webp",
    "category": "3D Spaces"
  },
  {
    "title": "IMU Transformations",
    "details": "Transform IMU data into different representations and coordinate systems with these code snippets.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/imu-transformations/"
    },
    "image": "/alpha-lab/imu-transformations.webp",
    "category": "3D Spaces"
  },
  {
    "title": "Automate Event Annotations With Pupil Cloud and GPT",
    "details": "Automatically annotate important activities and events in your Pupil Cloud recordings with GPT-4o.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/event-automation-gpt/"
    },
    "image": "/alpha-lab/event-annotation.webp",
    "category": "Building with AI"
  },
  {
    "title": "Map Gaze Onto an Alternative Egocentric Video",
    "details": "Automatically map gaze from Neon scene camera to an alternative concurrent egocentric video.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/egocentric-video-mapper/"
    },
    "image": "/alpha-lab/egocentric-video-mapper.webp",
    "category": "3D Spaces"
  },
  {
    "title": "Audio-Based Event Detection With Pupil Cloud and OpenAI's Whisper",
    "details": "Automatically annotate important events in your Pupil Cloud recordings using Neon's audio capture and OpenAI's Whisper.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/audio-event-annotations/"
    },
    "image": "/alpha-lab/audio-events-img.webp",
    "category": "Building with AI"
  },
  {
    "title": "Where did I see that? Eye Tracking & GPS",
    "details": "Use a GPS, like the one in Neon's Companion Device, to record synchronized location, eye, and head movement data. Visualize it on a map and click to jump there in your recording!",
    "link": {
      "text": "View",
      "href": "/alpha-lab/gps/"
    },
    "image": "/alpha-lab/gps.webp",
    "category": "3D Spaces"
  },
  {
    "title": "Real-Time Eyelid Dynamics with PERCLOS and Neon",
    "details": "Calculate PERCLOS (percentage of eye closure) in real time using Neon and its Real-Time API. ",
    "link": {
      "text": "View",
      "href": "/alpha-lab/perclos/"
    },
    "image": "/alpha-lab/perclos.webp",
    "category": "Real Time & Interactive"
  },
  {
    "title": "Map Gaze Onto Anything",
    "details": "Combine gaze with object and pose recognition in minutes. Learn how to augment your eye tracking data using powerful, open-source computer vision models, in real time or after the fact.",
    "link": {
      "text": "View",
      "href": "/alpha-lab/map-onto-anything/"
    },
    "image": "/alpha-lab/map-gaze-anything.webp",
    "category": "Real Time & Interactive"
  },
  {
    "title": "Dynamic AOIs with SAM2",
    "details": "Segment and map gaze onto any moving area of interest using Neon and SAM2",
    "link": {
      "text": "View",
      "href": "/alpha-lab/dynamic-aoi-sam2/"
    },
    "image": "/alpha-lab/sam2.webp",
    "category": "Building with AI"
  }
]